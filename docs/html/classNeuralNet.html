<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>BreakingCaptcha: NeuralNet Class Reference</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.3 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
    <li><a href="files.html"><span>Files</span></a></li>
  </ul>
</div>
<div class="tabs">
  <ul>
    <li><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
    <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
  </ul>
</div>
<h1>NeuralNet Class Reference</h1><!-- doxytag: class="NeuralNet" --><code>#include &lt;NeuralNet.h&gt;</code>
<p>

<p>
<a href="classNeuralNet-members.html">List of all members.</a><table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#a7045d229a664d8209a919d93108426a">NeuralNet</a> (int <a class="el" href="classNeuralNet.html#d46f938b28b505ef25f9d0a3a256ba78">numInput</a>, int <a class="el" href="classNeuralNet.html#62cfa0d0238baf0239429fbefd63042c">numHidden</a>, int <a class="el" href="classNeuralNet.html#c20e9fd588f7be05e8d658a5b673affe">numOutput</a>)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#ae2e3914f799ae37da4f3d088e5259db">train</a> ()</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#3ae443739e4e6a6c0d86d5149bde706f">compute</a> ()</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#f36ed795560a187aaafc86b82348ae05">calculateNeuronValues</a> (<a class="el" href="classGenericLayer.html">GenericLayer</a> *layer)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#8a49e8b1bf5710e27c57b322ee3bc323">logisticActivation</a> (double x)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#ec1f7f481954c7a3eafdefc8d23070f8">alterWeights</a> (<a class="el" href="classGenericLayer.html">GenericLayer</a> *layer)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#ae5a77ddecea2c9f0c11feb0089dbb03">calculateMSE</a> ()</td></tr>

<tr><td colspan="2"><br><h2>Public Attributes</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#dbc3025a07c81b26fddcc6f376f69cd1">learningRate</a> = 0.25</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#48dd706c84da839dca865eae8cdffc5e">maxTrainingIterations</a> = 1000</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#a8329b04a9c709b1b508b06dbec234bd">percentChange</a> = 0.01</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="classGenericLayer.html">GenericLayer</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#a254ed58d525fb163fe78e8ad2013d5e">input</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="classGenericLayer.html">GenericLayer</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#b0c566728137bb3bb4c3328005dcb33b">hidden</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="classGenericLayer.html">GenericLayer</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#97e58ab98eff78a898e9bb68ebc5be11">output</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#d46f938b28b505ef25f9d0a3a256ba78">numInput</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#62cfa0d0238baf0239429fbefd63042c">numHidden</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#c20e9fd588f7be05e8d658a5b673affe">numOutput</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#db3310c1abfe25972101f3a5f9b45d1e">desiredOutput</a></td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classNeuralNet.html#a767b858e21d79356577a77f927080fa">inputData</a></td></tr>

</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
This class brings together the work done by various parts of the Neural system. It is the binding layer between the neural layers and the data structures inherent in the system. As such, it is responsible for initializing, stucturing, training, and calculating the neural network environment. <hr><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" name="a7045d229a664d8209a919d93108426a"></a><!-- doxytag: member="NeuralNet::NeuralNet" ref="a7045d229a664d8209a919d93108426a" args="(int numInput, int numHidden, int numOutput)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">NeuralNet::NeuralNet           </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>numInput</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>numHidden</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>numOutput</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>numInput</em>&nbsp;</td><td>The number of neurons to create in the input layer. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>numHidden</em>&nbsp;</td><td>The number of neurons to create in the hidden layer. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>numOutput</em>&nbsp;</td><td>The number of neurons to create in the output layer. </td></tr>
  </table>
</dl>

</div>
</div><p>
<hr><h2>Member Function Documentation</h2>
<a class="anchor" name="ae2e3914f799ae37da4f3d088e5259db"></a><!-- doxytag: member="NeuralNet::train" ref="ae2e3914f799ae37da4f3d088e5259db" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void NeuralNet::train           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl class="pre" compact><dt><b>Precondition:</b></dt><dd>The trainingData and desiredValues arrays have been assigned and are of the appropriate dimensions for this particular NN. </dd></dl>
<dl class="post" compact><dt><b>Postcondition:</b></dt><dd>All the weights and biases are set according to the trainingData and the NN is ready for real environment data. </dd></dl>

</div>
</div><p>
<a class="anchor" name="3ae443739e4e6a6c0d86d5149bde706f"></a><!-- doxytag: member="NeuralNet::compute" ref="3ae443739e4e6a6c0d86d5149bde706f" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void NeuralNet::compute           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl class="pre" compact><dt><b>Precondition:</b></dt><dd>The NN has been initialized and trained, and the inputData array has been assigned and is of the appropriate dimensions for this particular NN. </dd></dl>
<dl class="post" compact><dt><b>Postcondition:</b></dt><dd>The output layer nodes now contain, based on the NN's weights and biases, the output values for the given data set. </dd></dl>

</div>
</div><p>
<a class="anchor" name="f36ed795560a187aaafc86b82348ae05"></a><!-- doxytag: member="NeuralNet::calculateNeuronValues" ref="f36ed795560a187aaafc86b82348ae05" args="(GenericLayer *layer)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void NeuralNet::calculateNeuronValues           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classGenericLayer.html">GenericLayer</a> *&nbsp;</td>
          <td class="paramname"> <em>layer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
To calculate the value of each neuron we calculate the sum of the weights connected to each neuron multiplied by the value of each corresponding neuronal value, finally adding the adjusted bias and passing this value through an activation function.<p>
The formula we use is given as follows, where <img class="formulaInl" alt="$y_i$" src="form_3.png"> is the i-th neuron on the parent layer and <img class="formulaInl" alt="$w_{ji}$" src="form_4.png"> is the weight from the parent to the neuron whose value we are calculating (note that in this notation, for simplicity, we denote the bias and its weight as the first element): <img class="formulaInl" alt="$\displaystyle v_j(n) = \sum_{i=0}^n y_i(n)w_{ji}(n)$" src="form_5.png"><p>
And similarly we note that the final value of this neuron is <img class="formulaInl" alt="$y(n)_j = \phi_j(v_j(n))$" src="form_10.png"> where <img class="formulaInl" alt="$\phi_j()$" src="form_9.png"> is the activation function on neuron j. 
</div>
</div><p>
<a class="anchor" name="8a49e8b1bf5710e27c57b322ee3bc323"></a><!-- doxytag: member="NeuralNet::logisticActivation" ref="8a49e8b1bf5710e27c57b322ee3bc323" args="(double x)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double NeuralNet::logisticActivation           </td>
          <td>(</td>
          <td class="paramtype">double&nbsp;</td>
          <td class="paramname"> <em>x</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Used for computing the value of a neuron after calculating the raw value. We use an easily differentiable function so that it is easier later on to calculate the change in weights. The particular function we use here is the sigmoidal activation function, which constrains the output to between 0 and +1, a good fit for NNs.<p>
The precise function we use is <img class="formulaInl" alt="$\displaystyle\phi_j(x) = \frac{1}{1 + exp(-x)}$" src="form_13.png">. 
</div>
</div><p>
<a class="anchor" name="ec1f7f481954c7a3eafdefc8d23070f8"></a><!-- doxytag: member="NeuralNet::alterWeights" ref="ec1f7f481954c7a3eafdefc8d23070f8" args="(GenericLayer *layer)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void NeuralNet::alterWeights           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classGenericLayer.html">GenericLayer</a> *&nbsp;</td>
          <td class="paramname"> <em>layer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
We calculate the errors of the each of the neurons in the NN here for use in adjusting their weights and biases for training purposes. There are three main cases for a three layer feed forward NN.<p>
The first is the input layer, and since the desired value is always equal to the actual value, since it is given, the gradient is 0.<p>
The second is the case of a hidden layer, where the errors are calculated from the layer nearest to the output layer to the layer closest to the input layer. This is done using the back propogation algorithm, which, given the gradients of adjacent layers, calculates the gradients recursively working backwords and using the derivative of the activation function used for calculating neuron values. This is done since the error signals cannot be determined for hidden layers since there is no value to compare their output to. It can be written as <img class="formulaInl" alt="$\displaystyle\gamma_j(n) = \phi_j^`(v_j(n))\sum_{k=0}^m \gamma_k(n)w_{kj}(n)$" src="form_17.png"> where neuron j is the gradient we are calculating, neuron k is in the child layer and m is the number of neurons on that layer.<p>
The third case is the output layer, where the error is trivially desired-actual. The gradient is then defined much the same as case 2 where it is the error multiplied by the derivative of the activation function applied to the value of the neuron. It can be written as <img class="formulaInl" alt="$\displaystyle\gamma_j(n) = e_j(n)\phi_j^`(v_j(n))$" src="form_14.png">.<p>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>layer</em>&nbsp;</td><td>The layer for which we are to calculate the errors. </td></tr>
  </table>
</dl>

</div>
</div><p>
<a class="anchor" name="ae5a77ddecea2c9f0c11feb0089dbb03"></a><!-- doxytag: member="NeuralNet::calculateMSE" ref="ae5a77ddecea2c9f0c11feb0089dbb03" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double NeuralNet::calculateMSE           </td>
          <td>(</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl class="return" compact><dt><b>Returns:</b></dt><dd>The mean squared error of the output layer. </dd></dl>

</div>
</div><p>
<hr><h2>Member Data Documentation</h2>
<a class="anchor" name="dbc3025a07c81b26fddcc6f376f69cd1"></a><!-- doxytag: member="NeuralNet::learningRate" ref="dbc3025a07c81b26fddcc6f376f69cd1" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="classNeuralNet.html#dbc3025a07c81b26fddcc6f376f69cd1">NeuralNet::learningRate</a> = 0.25          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This variable controls the rate at which the network learns. It is responsible for smoothing out the learning functions. 
</div>
</div><p>
<a class="anchor" name="48dd706c84da839dca865eae8cdffc5e"></a><!-- doxytag: member="NeuralNet::maxTrainingIterations" ref="48dd706c84da839dca865eae8cdffc5e" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classNeuralNet.html#48dd706c84da839dca865eae8cdffc5e">NeuralNet::maxTrainingIterations</a> = 1000          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The max number of iterations to compute while training. 
</div>
</div><p>
<a class="anchor" name="a8329b04a9c709b1b508b06dbec234bd"></a><!-- doxytag: member="NeuralNet::percentChange" ref="a8329b04a9c709b1b508b06dbec234bd" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double <a class="el" href="classNeuralNet.html#a8329b04a9c709b1b508b06dbec234bd">NeuralNet::percentChange</a> = 0.01          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
When to stop the training based on each epoch's mean squared error. A percentage of the rate of change. 
</div>
</div><p>
<a class="anchor" name="a254ed58d525fb163fe78e8ad2013d5e"></a><!-- doxytag: member="NeuralNet::input" ref="a254ed58d525fb163fe78e8ad2013d5e" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classGenericLayer.html">GenericLayer</a>* <a class="el" href="classNeuralNet.html#a254ed58d525fb163fe78e8ad2013d5e">NeuralNet::input</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The input layer to the neural network. 
</div>
</div><p>
<a class="anchor" name="b0c566728137bb3bb4c3328005dcb33b"></a><!-- doxytag: member="NeuralNet::hidden" ref="b0c566728137bb3bb4c3328005dcb33b" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classGenericLayer.html">GenericLayer</a>* <a class="el" href="classNeuralNet.html#b0c566728137bb3bb4c3328005dcb33b">NeuralNet::hidden</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The hidden layer to the neural network. 
</div>
</div><p>
<a class="anchor" name="97e58ab98eff78a898e9bb68ebc5be11"></a><!-- doxytag: member="NeuralNet::output" ref="97e58ab98eff78a898e9bb68ebc5be11" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classGenericLayer.html">GenericLayer</a>* <a class="el" href="classNeuralNet.html#97e58ab98eff78a898e9bb68ebc5be11">NeuralNet::output</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The output layer to the neural network. 
</div>
</div><p>
<a class="anchor" name="d46f938b28b505ef25f9d0a3a256ba78"></a><!-- doxytag: member="NeuralNet::numInput" ref="d46f938b28b505ef25f9d0a3a256ba78" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classNeuralNet.html#d46f938b28b505ef25f9d0a3a256ba78">NeuralNet::numInput</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The number of input neurons to create. 
</div>
</div><p>
<a class="anchor" name="62cfa0d0238baf0239429fbefd63042c"></a><!-- doxytag: member="NeuralNet::numHidden" ref="62cfa0d0238baf0239429fbefd63042c" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classNeuralNet.html#62cfa0d0238baf0239429fbefd63042c">NeuralNet::numHidden</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The number of hidden neurons to create. 
</div>
</div><p>
<a class="anchor" name="c20e9fd588f7be05e8d658a5b673affe"></a><!-- doxytag: member="NeuralNet::numOutput" ref="c20e9fd588f7be05e8d658a5b673affe" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classNeuralNet.html#c20e9fd588f7be05e8d658a5b673affe">NeuralNet::numOutput</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The number of output neurons to create. 
</div>
</div><p>
<a class="anchor" name="db3310c1abfe25972101f3a5f9b45d1e"></a><!-- doxytag: member="NeuralNet::desiredOutput" ref="db3310c1abfe25972101f3a5f9b45d1e" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double* <a class="el" href="classNeuralNet.html#db3310c1abfe25972101f3a5f9b45d1e">NeuralNet::desiredOutput</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The expected results from the training data. Each element is related to each output neuron's expected value 
</div>
</div><p>
<a class="anchor" name="a767b858e21d79356577a77f927080fa"></a><!-- doxytag: member="NeuralNet::inputData" ref="a767b858e21d79356577a77f927080fa" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double* <a class="el" href="classNeuralNet.html#a767b858e21d79356577a77f927080fa">NeuralNet::inputData</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
The data to be calculated from the environment, in the same form as each set of data in trainingData. 
</div>
</div><p>
<hr>The documentation for this class was generated from the following files:<ul>
<li>src/<a class="el" href="NeuralNet_8h.html">NeuralNet.h</a><li>src/<a class="el" href="NeuralNet_8cpp.html">NeuralNet.cpp</a></ul>
<hr size="1"><address style="text-align: right;"><small>Generated on Mon Nov 5 08:57:15 2007 for BreakingCaptcha by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.3 </small></address>
</body>
</html>
